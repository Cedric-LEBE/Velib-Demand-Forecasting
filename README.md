# Projet VÃ©lib - PrÃ©diction de la demande de vÃ©los

## ğŸ“‹ Description du projet

Ce projet vise Ã  dÃ©velopper un modÃ¨le prÃ©dictif pour anticiper la demande de vÃ©los en libre-service (type VÃ©lib). L'objectif est d'aider l'organisme de gestion Ã  optimiser l'organisation de ses Ã©quipes de maintenance pour mieux rÃ©pondre aux besoins des clients.

## ğŸ¯ Objectif

PrÃ©dire le nombre de locations de vÃ©los (`cnt`) en fonction de diverses variables mÃ©tÃ©orologiques et temporelles afin d'optimiser la gestion des Ã©quipes de maintenance.

## ğŸ“Š Dataset

Le dataset contient 17 379 observations avec les variables suivantes :

### Variables explicatives
- **instant** : Index du relevÃ©
- **dteday** : Date du relevÃ©
- **season** : Saison (1=hiver, 2=printemps, 3=Ã©tÃ©, 4=automne)
- **mnth** : Mois (1-12)
- **hr** : Heure (0-23)
- **holiday** : Jour de vacances scolaires (boolÃ©en)
- **weekday** : Jour de la semaine (0-6)
- **weathersit** : Conditions mÃ©tÃ©o (1=dÃ©gagÃ©, 2=brouillard, 3=lÃ©gÃ¨re pluie/neige, 4=fortes averses)
- **temp** : TempÃ©rature en Â°C
- **atemp** : TempÃ©rature ressentie en Â°C
- **hum** : Taux d'humiditÃ©
- **windspeed** : Vitesse du vent

### Variable cible
- **count** â€“ nombre total de locations de vÃ©los 

## ğŸ› ï¸ Technologies utilisÃ©es

- **Python 3.8+**
- **pandas** : Manipulation et analyse de donnÃ©es
- **numpy** : Calculs numÃ©riques
- **matplotlib** & **seaborn** : Visualisation de donnÃ©es
- **scikit-learn** : Machine Learning
  - Random Forest Regressor
  - K-Means Clustering
  - GridSearchCV pour l'optimisation des hyperparamÃ¨tres

## ğŸ“ Structure du projet

```
Velib-Demand-Forecasting/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ input/
â”‚       â””â”€â”€ velo.csv           # Dataset principal
â”œâ”€â”€ training.ipynb             # Notebook d'analyse et modÃ©lisation
â”œâ”€â”€ pyproject.toml             # Configuration du projet
â””â”€â”€ README.md                  # Ce fichier
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- pip ou conda

### Ã‰tape 1 : CrÃ©er un environnement virtuel

```bash
# CrÃ©er un environnement virtuel
python3 -m venv .venv

# Activer l'environnement virtuel
# Sur macOS/Linux :
source .venv/bin/activate

# Sur Windows :
venv\Scripts\activate
```

### Ã‰tape 2 : Installation des dÃ©pendances

```bash
# Avec pip
pip install -e .

# Ou installer les dÃ©pendances directement
pip install pandas numpy matplotlib seaborn scikit-learn jupyter ipykernel
```

### Ã‰tape 3 : Configuration du kernel Jupyter

Pour utiliser l'environnement virtuel dans Jupyter, il faut l'enregistrer comme kernel :

```bash
# S'assurer que l'environnement virtuel est activÃ©
python -m ipykernel install --user --name=velib-env --display-name="Python (Velib)"
```

Ensuite, lors de l'ouverture du notebook dans Jupyter ou VS Code :
1. Ouvrir `training.ipynb`
2. SÃ©lectionner le kernel "Python (Velib)" dans le menu de sÃ©lection du kernel
3. Le notebook utilisera dÃ©sormais l'environnement virtuel avec toutes les dÃ©pendances installÃ©es

## ğŸ“ˆ MÃ©thodologie

### 1. Exploration des donnÃ©es
- Analyse de la qualitÃ© des donnÃ©es (valeurs manquantes, aberrantes)
- Visualisation des distributions et corrÃ©lations
- Identification des patterns temporels et mÃ©tÃ©orologiques

### 2. Feature Engineering
CrÃ©ation de nouvelles variables :
- `is_weekend` : Indicateur weekend/semaine
- `is_rush_hour` : Indicateur heures de pointe (7-9h et 17-19h)
- `temp_humidity_interaction` : Interaction tempÃ©rature Ã— humiditÃ©

### 3. Approche non-supervisÃ©e
- K-Means clustering pour identifier des profils de demande similaires
- Analyse via PCA (Principal Component Analysis)

### 4. ModÃ©lisation prÃ©dictive
- **Algorithme** : Random Forest Regressor
- **Pipeline** : Preprocessing automatique (OneHotEncoding pour variables catÃ©gorielles)
- **Validation** : Split train/test (80/20)
- **Optimisation** : GridSearchCV avec validation croisÃ©e (5-fold)

### 5. MÃ©triques d'Ã©valuation
- **RMSE** (Root Mean Squared Error) : Erreur quadratique moyenne
- **MAE** (Mean Absolute Error) : Erreur absolue moyenne
- **RÂ²** : Coefficient de dÃ©termination

## ğŸ“Š RÃ©sultats

### Observations clÃ©s
- Forte corrÃ©lation entre la demande et :
  - La tempÃ©rature (r=0.40)
  - Les heures de la journÃ©e (r=0.39)
  - L'humiditÃ© (r=-0.32)
- Impact significatif des saisons et conditions mÃ©tÃ©orologiques
- Patterns distincts entre jours de semaine et weekends
- Pics de demande aux heures de pointe

### Performance du modÃ¨le
Le modÃ¨le Random Forest optimisÃ© offre une bonne capacitÃ© prÃ©dictive avec un RÂ² Ã©levÃ© et un faible RMSE, permettant une planification efficace des Ã©quipes de maintenance.

## ğŸ” Utilisation

1. Ouvrir le notebook Jupyter :
```bash
jupyter notebook training.ipynb
```

2. ExÃ©cuter les cellules sÃ©quentiellement pour :
   - Charger et explorer les donnÃ©es
   - Effectuer le feature engineering
   - EntraÃ®ner les modÃ¨les
   - Ã‰valuer les performances

## ğŸ“ Points d'attention

- **Valeurs manquantes** : 1 664 valeurs manquantes pour l'humiditÃ© (~9.6%)
- **MulticolinÃ©aritÃ©** : Variables `casual` et `registered` exclues du modÃ¨le (composantes de `cnt`)
- **RÃ©gularisation** : ParamÃ¨tres ajustÃ©s pour Ã©viter le sur-apprentissage

